{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Patrik_Svensson_lab_7_Differentials.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzXqQuR0rkSZ",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/drive/1rAiWyPGy48Mrj4Rl3DVvgfMNP4ppzetC\n",
        "\n",
        "# **Lab 7 : Optimization and learning**\n",
        "**Patrik Svensson**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZYEoltJtjGY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Abstract**\n",
        "In this lab we have explored the concept of optimization and learning. In optmization the we want to find a critical point for a function. To find the critical point we can use an iteration method, where we stop the iteration when we are close enough to the correct answer. The result is an implementation of gradient decent method in $R^n$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cs_Tl5CtntJ",
        "colab_type": "text"
      },
      "source": [
        "# **Set up environment**\n",
        "To set up the environment, run the two following lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9snxAtSVfb1b",
        "colab_type": "code",
        "outputId": "0c56f4ed-df04-4e1a-954a-fcba9bff1124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install numdifftools\n",
        "\n",
        "import numpy as np\n",
        "import unittest\n",
        "import math\n",
        "from scipy.optimize import fmin\n",
        "import scipy\n",
        "import random\n",
        "import numdifftools"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numdifftools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c0/b0d967160ecc8db52ae34e063937d85e8d386f140ad4826aae2086245a5e/numdifftools-0.9.39-py2.py3-none-any.whl (953kB)\n",
            "\r\u001b[K     |▍                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 962kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: numdifftools\n",
            "Successfully installed numdifftools-0.9.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqLm9OORtrkY",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "This lab is all about optmization. Optimization problems are about finding a minimum or maximum points of a function, also known as critical points. In this lab we will explore some iterative methods for solving several optimization problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q0xsxBntx6M",
        "colab_type": "text"
      },
      "source": [
        "# **Methods**\n",
        "In this chapter, I will present how the implementation of the functions was conducted. The study was conducted in the following way.\n",
        "\n",
        "1.   Literature research\n",
        "2.   Implementation\n",
        "3.   Testing\n",
        "\n",
        "In the sections below, I have provided a reference to where the algorithms were founded, or how it was deduced, followed with a code implementation in Python, and lastly unit test for the assurance of the accuracy of the implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbZShRHWt2QN",
        "colab_type": "text"
      },
      "source": [
        "# Gradient descent method in $R^n$ \n",
        "When talking about minimization problems in $R^n$, it is about finding a $x^* \\in D$ that satisfies the following inequality from the lecture notes 15.1.\n",
        "\n",
        "$f(x^*) \\leq f(x)$, $\\forall x \\in D$\n",
        "\n",
        "Where $D$ is a search space for a solution to the inequality. The function $f$ can be defined as $f: D \\rightarrow R$.\n",
        "\n",
        "One method of finding a minimum is the *gradient descent method*. the gradient descent method, the algorithm in the following way:\n",
        "\n",
        "\n",
        "1.   Choose initial value for point $x$ in $R^n$ \n",
        "2.   Find $\\nabla f(x)$\n",
        "3.   Go as long in the direction of $-\\nabla f(x)$ from point $x$ until the reached point has you reach a point where $\\nabla f(x_{min})$ is close to zero, or $x_{new}$ where $\\langle\\nabla f(x), \\nabla f(x_{orto})\\rangle = 0$. If $\\nabla f(x_{min})$  is reached the search for minimum is finished, otherwise iterate from step 2 with $x = x_{orto}.$\n",
        "\n",
        "This algorithm is implemented below in python, togheter with unit tests. This code is based on the pseudo code in the lecture notes 15.2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYKu3_7SgYEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOL = 0.001\n",
        "\n",
        "def gradient_descent_method(f, x0):\n",
        "  x = x0\n",
        "  df = compute_gradient(f, x)\n",
        "  while np.linalg.norm(df) > TOL:\n",
        "    df = compute_gradient(f, x)\n",
        "    alpha = get_step_length(f, df, x)\n",
        "    x = x - alpha * df / np.linalg.norm(df)\n",
        "  return x\n",
        "\n",
        "def compute_gradient(f, x):\n",
        "  # Let's take a sufficient small delta size\n",
        "  delta_size = np.sqrt(np.finfo(float).eps)\n",
        "  epsilon = np.full(x.shape[0], delta_size)\n",
        "  return scipy.optimize.approx_fprime(x, f, epsilon)\n",
        "\n",
        "def get_step_length(f, df, x):\n",
        "  step = 0.0001\n",
        "  norm_df = df / np.linalg.norm(df)\n",
        "  \n",
        "  i = 0\n",
        "  while True:\n",
        "    gradient = compute_gradient(f, x - norm_df * i * step)\n",
        "    if(np.linalg.norm(gradient) < TOL or (np.inner(gradient, norm_df) < TOL and np.inner(gradient, norm_df) > -TOL)):\n",
        "      return i * step\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trICA1NweoPL",
        "colab_type": "text"
      },
      "source": [
        "Below are unit test to assure the implementation of the gradient decent method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsKJKYxDIFeh",
        "colab_type": "code",
        "outputId": "8e9b47c5-0dbc-4286-9cec-47fb1a299bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "class TestEulerMethod(unittest.TestCase): \n",
        "  def test_accuracy_2D(self):\n",
        "    for i in range(10):\n",
        "      a = random.uniform(-10, 10)\n",
        "      b = random.uniform(-10, 10)\n",
        "      function = lambda x: (x[0] + a)**2 + (x[1] + b)**2\n",
        "      expected_result = fmin(function, np.array([1,2]), disp=False)\n",
        "\n",
        "      result = gradient_descent_method(function, np.array([0, 0]))\n",
        "      np.testing.assert_almost_equal(result, expected_result, 1)\n",
        "\n",
        "  def test_accuracy_3D(self):\n",
        "    for i in range(10):\n",
        "      a = random.uniform(-10, 10)\n",
        "      b = random.uniform(-10, 10)\n",
        "      c = random.uniform(-10, 10)\n",
        "      function = lambda x: (x[0] + a)**2 + (x[1] + b)**2 + (x[2] + c)**2\n",
        "      expected_result = fmin(function, np.array([0, 0, 0]), disp=False)\n",
        "\n",
        "      result = gradient_descent_method(function, np.array([0, 0, 0]))\n",
        "      np.testing.assert_almost_equal(result, expected_result, 1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "    # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 64.707s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ3cdvSoxCnT",
        "colab_type": "text"
      },
      "source": [
        "# Newton's method in $R^n$\n",
        "\n",
        "Newton's method in $R^n$ is based on Taylor's formula:\n",
        "\n",
        "$f(x) \\approx f(y) + \\nabla f(y)^T(x-y + \\frac{1}{2}(x-y)^THf(y)(x-y)$\n",
        "\n",
        "If we substitute x with $x^{k+1}$ and y with $x^k$ and diffrentiate $f(x)$ and let it be equal to zero, we get:\n",
        "\n",
        "$\\frac{df(x^{(k+1)})}{d(\\Delta x)} = \\frac{d}{d(\\Delta x)}(f(x^k) + \\nabla f(x^k)*\\Delta x + \\frac{1}{2}\\Delta x^T Hf(x^k)\\Delta x) = $\n",
        "\n",
        "$\\nabla f(x^k) + Hf(x^k)\\Delta x = 0$\n",
        "\n",
        "Where $\\Delta x = x^{k + 1} + x^k$\n",
        "\n",
        "To get $\\Delta x$ by: \n",
        "\n",
        "$\\Delta x = -\\frac{\\nabla f(x^k)}{Hf(x^k)}$\n",
        "\n",
        "With  $\\Delta x$ we can retrieve $x^{k+1}$.\n",
        "\n",
        "In Newton's method we will reiterate the calculation of $x^{k+1}$ until it's close enough to the minimum.\n",
        "\n",
        "This code is based on the pseudo code in the lecture notes 15.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeVATRD8TNQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient(f, x):\n",
        "  delta_size = np.sqrt(np.finfo(float).eps)\n",
        "  epsilon = np.full(x.shape[0], delta_size)\n",
        "  return scipy.optimize.approx_fprime(x, f, epsilon)\n",
        "\n",
        "def compute_hessian(f, x):\n",
        "  return numdifftools.Hessian(f)(x)\n",
        "\n",
        "def solve_linear_system(a, b):\n",
        "  return np.linalg.solve(a, b)\n",
        "\n",
        "def newton_method(f, x0):\n",
        "  x = x0\n",
        "  df = compute_gradient(f, x)\n",
        "  TOL = 0.01\n",
        "\n",
        "  while np.linalg.norm(df) > TOL:\n",
        "    df = compute_gradient(f, x)\n",
        "    hf = compute_hessian(f, x)\n",
        "    dx = solve_linear_system(hf, -df)\n",
        "    x = dx + x\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOKQo5Qaw6MP",
        "colab_type": "text"
      },
      "source": [
        "The code below is the implementation of unit tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZs71INWxBqF",
        "colab_type": "code",
        "outputId": "b6c6eac9-6fb4-4b7d-e932-e78e1a8d922e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "class TestEulerMethod(unittest.TestCase): \n",
        "  def test_accuracy_2D(self):\n",
        "    for i in range(10):\n",
        "      a = random.uniform(-10, 10)\n",
        "      b = random.uniform(-10, 10)\n",
        "      function = lambda x: (x[0] + a)**2 + (x[1] + b)**2\n",
        "      expected_result = fmin(function, np.array([1,2]), disp=False)\n",
        "\n",
        "      result = newton_method(function, np.array([0, 0]))\n",
        "      np.testing.assert_almost_equal(result, expected_result, 1)\n",
        "\n",
        "  def test_accuracy_3D(self):\n",
        "    for i in range(10):\n",
        "      a = random.uniform(-10, 10)\n",
        "      b = random.uniform(-10, 10)\n",
        "      c = random.uniform(-10, 10)\n",
        "      function = lambda x: (x[0] + a)**2 + (x[1] + b)**2 + (x[2] + c)**2\n",
        "      expected_result = fmin(function, np.array([0, 0, 0]), disp=False)\n",
        "\n",
        "      result = newton_method(function, np.array([0, 0, 0]))\n",
        "      np.testing.assert_almost_equal(result, expected_result, 1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "    # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.286s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIJVVR2ht8vX",
        "colab_type": "text"
      },
      "source": [
        "# **Results**\n",
        "\n",
        "The results of this lab is an implementation of gradient descent method, and newtons method, both in $R^n$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duHpPRhLOzFA",
        "colab_type": "code",
        "outputId": "f38d78b8-6c68-4df5-ef30-3859067423d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Help from user Pierre S. in the stack overflow thread to give the main arguments: \n",
        "    # https://stackoverflow.com/questions/49952317/python3-for-unit-test-attributeerror-module-main-has-no-attribute-kerne \n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.284s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC8f7T82uAno",
        "colab_type": "text"
      },
      "source": [
        "# **Discussion**\n",
        "The gradient descent method take some serious time to perform when a decent precision is required and a more complex and higher dimensions are used. It would be intresting to solve a difficult problem with this problem together with more computing resources.\n",
        "\n"
      ]
    }
  ]
}