{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template-report-lab-X.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT20/blob/lindevanbeers/Lab-2/linde-report-lab-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "source": [
        "# **Lab 2: Matrix Factorization**\n",
        "**Linde van Beers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm",
        "colab_type": "text"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJipbXtnjrJZ",
        "colab_type": "text"
      },
      "source": [
        "3 methods are implemented in this report: Sparse matrix vector multiplication, QR factorisation, and solving of a linear system. All methods were tested and work. The latter 2 have only been implemented and tested for square matrices. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab_type": "code",
        "outputId": "be702948-b2d8-4940-eb0f-2507de986f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Author: Linde van Beers, 2020\n",
        "\n",
        "# Based on a template:\n",
        "# Copyright (C) 2019 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "source": [
        "In this report I show the implementation of 3 functions in linear algebra: Sparse matrix-vector product, QR-factorization and direct solve of a linear system. I used information as presented in the Lecture Notes of the course as guidelines for solving these problems. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeFO9QMeUOAu",
        "colab_type": "text"
      },
      "source": [
        "# **Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-qSrx2JkIFf",
        "colab_type": "text"
      },
      "source": [
        "### Sparse matrix-vector product\n",
        "\n",
        "This algorithm calculates the matrix vector product $Ax$ where $A$ is written in CRS form. I assumed that the row pointer has an extra element set to the number of non-zero elements in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zSvvQfFkN_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_MVP(x,A_val,col_idx, row_ptr):\n",
        "  # Assume that row_ptr has an extra element set to NNZ\n",
        "  n = len(row_ptr)-1\n",
        "  b = np.zeros(n)\n",
        "  for i in range(n):\n",
        "    for j in range(row_ptr[i], row_ptr[i+1]):\n",
        "      if col_idx[j] > len(x)-1:\n",
        "        return \"sizes do not match\"\n",
        "      b[i] += A_val[j]*x[col_idx[j]]\n",
        "  return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQnn9G7rFgeU",
        "colab_type": "text"
      },
      "source": [
        "### QR factorization\n",
        "\n",
        "I implemented the Householder QR factorisation algorithm as described in the lecture notes. \n",
        "I assumed A is a square matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dklghpfsXgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def qr_householder(A):\n",
        "  n = A.shape[1]\n",
        "  R = A.copy()\n",
        "  for k in range(n-1):\n",
        "    x = R[k:n,k]\n",
        "    v_k = x.copy()\n",
        "    v_k[0] = v_k[0]-np.sign(x[0])*np.linalg.norm(x)\n",
        "    v_k = v_k/np.linalg.norm(v_k)\n",
        "    for m in range(k,n):\n",
        "      R[k:n,m] = R[k:n,m]-(2*v_k*(np.dot(v_k.T,R[k:n,m])))  \n",
        "    Q_k = np.eye(n,n)\n",
        "    Q_k[k:n,k:n]= Q_k[k:n,k:n]-(2*(np.matmul(v_k,v_k.T))/np.dot(v_k.T,v_k))\n",
        "    if k==0:\n",
        "      Q = Q_k\n",
        "    else:\n",
        "      Q = np.matmul(Q.T,Q_k.T)\n",
        "  return Q,R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR6iWBXa4vLM",
        "colab_type": "text"
      },
      "source": [
        "### Direct solve\n",
        "\n",
        "In order to direct solve $Ax = b$ I first treated $A|b$ as a linear system and performed Gaussian elimination in order to get the system in row echelon form. This yielded an upper triangular matrix $A'$ and corresponding vector $b'$ on which I could then use backward substitution to find $x$, such that $A'x=b'$ and therefore $Ax=b$.\n",
        "I assumed A is a square matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWbl3wBu4vcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def direct_solve(A,b):\n",
        "  n = A.shape[1]\n",
        "  m = A.shape[0]\n",
        "  x = np.zeros(n)\n",
        "\n",
        "  # Put A and b in such a format that A is upper triangular\n",
        "  if A[0,0]==0:\n",
        "    for i in range(m):\n",
        "      if A[i,0] != 0:\n",
        "        A[0,:] = A[0,:] + A[i,:]/A[i,0]\n",
        "        b[0] = b[0] + b[i]/A[i,0]\n",
        "        break\n",
        "  for i in range(m-1):\n",
        "    for j in range(i+1,n):\n",
        "      c = A[j,i]/A[i,i]\n",
        "      A[j,:] = A[j,:] - c*A[i,:]\n",
        "      b[j] = b[j] - c*b[i]\n",
        "\n",
        "  # Use backward substitution to solve\n",
        "  x[n-1] = b[n-1]/A[n-1,n-1]\n",
        "  for i in range(n-2,-1,-1):\n",
        "    sum = 0\n",
        "    for j in range(i+1, n):\n",
        "      sum = sum +A[i,j]*x[j]\n",
        "    x[i] = (b[i]-sum)/A[i,i]\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trOKZ6HxsaV_",
        "colab_type": "text"
      },
      "source": [
        "### Sparse matrix-vector product\n",
        "\n",
        "I tested my function with a correct input and two incorrec inputs. The first, where $b$ is too small for $A$, gives an error as was intended. When $b$ is too large however, the algorithm just assumes that $A$ is also larger but just consists out of 0's in the columns that are 'missing'. This cannot be helped since a sparse matrix does not specify its dimensions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejWOxngcsf7N",
        "colab_type": "code",
        "outputId": "12db6b02-4395-438f-8dd4-766be9253222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "A = np.matrix([[0,1,0],[2,0,3],[0,0,4]])\n",
        "x = [1,2,3]\n",
        "print(\"A:\",A)\n",
        "print(\"x:\",x)\n",
        "# Create a sparse matrix object \n",
        "val = np.array([1,2,3,4])\n",
        "col_idx = np.array([1,0,2,2])\n",
        "row_ptr = np.array([0,1,3,4])\n",
        "# Print sparse matrix object attributes\n",
        "print('Sparse matrix values: \\n',val)\n",
        "print('Sparse matrix column indices: \\n',col_idx)\n",
        "print('Sparse matrix row pointer: \\n',row_ptr)\n",
        "# Calculate b using the sparse matrix\n",
        "b = sparse_MVP(x, val, col_idx, row_ptr)\n",
        "# Calculate b using dense matrix \n",
        "bAns = A*np.matrix(x).T\n",
        "print(\"dense matrix-vector product:\",bAns.T)\n",
        "print(\"sparse matrix-vector product:\",b)\n",
        "\n",
        "A = np.matrix([[0,4,0,-4],[2,0,0,3],[0,0,0,5]])\n",
        "x = [5,7,2]\n",
        "print(\"\\nA:\",A)\n",
        "print(\"x:\",x)\n",
        "# Create a sparse matrix object \n",
        "val = np.array([4,-4,2,3,5])\n",
        "col_idx = np.array([1,3,0,3,3])\n",
        "row_ptr = np.array([0,2,4,5])\n",
        "# Print sparse matrix object attributes\n",
        "print('Sparse matrix values: \\n',val)\n",
        "print('Sparse matrix column indices: \\n',col_idx)\n",
        "print('Sparse matrix row pointer: \\n',row_ptr)\n",
        "# Calculate b using the sparse matrix\n",
        "b = sparse_MVP(x, val, col_idx, row_ptr)\n",
        "print(\"answer by function:\",b)\n",
        "\n",
        "A = np.matrix([[0,4,0,-4],[2,0,0,3],[0,0,0,5]])\n",
        "x = [5,7,2,4,5]\n",
        "print(\"\\nA:\",A)\n",
        "print(\"x:\",x)\n",
        "# Create a sparse matrix object \n",
        "val = np.array([4,-4,2,3,5])\n",
        "col_idx = np.array([1,3,0,3,3])\n",
        "row_ptr = np.array([0,2,4,5])\n",
        "# Print sparse matrix object attributes\n",
        "print('Sparse matrix values: \\n',val)\n",
        "print('Sparse matrix column indices: \\n',col_idx)\n",
        "print('Sparse matrix row pointer: \\n',row_ptr)\n",
        "# Calculate b using the sparse matrix\n",
        "b = sparse_MVP(x, val, col_idx, row_ptr)\n",
        "print(\"answer by function:\",b)\n",
        "print('''CSR format has minimum size, not maximum, \n",
        "because there could be 0's going each direction. ''')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: [[0 1 0]\n",
            " [2 0 3]\n",
            " [0 0 4]]\n",
            "x: [1, 2, 3]\n",
            "Sparse matrix values: \n",
            " [1 2 3 4]\n",
            "Sparse matrix column indices: \n",
            " [1 0 2 2]\n",
            "Sparse matrix row pointer: \n",
            " [0 1 3 4]\n",
            "dense matrix-vector product: [[ 2 11 12]]\n",
            "sparse matrix-vector product: [ 2. 11. 12.]\n",
            "\n",
            "A: [[ 0  4  0 -4]\n",
            " [ 2  0  0  3]\n",
            " [ 0  0  0  5]]\n",
            "x: [5, 7, 2]\n",
            "Sparse matrix values: \n",
            " [ 4 -4  2  3  5]\n",
            "Sparse matrix column indices: \n",
            " [1 3 0 3 3]\n",
            "Sparse matrix row pointer: \n",
            " [0 2 4 5]\n",
            "answer by function: sizes do not match\n",
            "\n",
            "A: [[ 0  4  0 -4]\n",
            " [ 2  0  0  3]\n",
            " [ 0  0  0  5]]\n",
            "x: [5, 7, 2, 4, 5]\n",
            "Sparse matrix values: \n",
            " [ 4 -4  2  3  5]\n",
            "Sparse matrix column indices: \n",
            " [1 3 0 3 3]\n",
            "Sparse matrix row pointer: \n",
            " [0 2 4 5]\n",
            "answer by function: [12. 22. 20.]\n",
            "CSR format has minimum size, not maximum, \n",
            "because there could be 0's going each direction. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7nWxG2BOl8m",
        "colab_type": "text"
      },
      "source": [
        "### QR Factorization\n",
        "\n",
        "My algorithm works on square matrices. The second test does give some small errors because the program rounds 1/3 and 2/3, introducing some computational error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFLRt55WOtK-",
        "colab_type": "code",
        "outputId": "d218c9cd-968f-4ab8-a9dd-6dca062fe090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "A = np.matrix([[12.,-51.,4.],[6.,167.,-68.],[-4.,24.,-41.]])\n",
        "print(\"A\",A)\n",
        "Q,R = qr_householder(A)\n",
        "print(\"Q\",Q)\n",
        "print(\"R\",R)\n",
        "print(\"QR\", np.matmul(Q,R))\n",
        "print(\"||(Q^TQ)-I||_F:\", np.linalg.norm(np.matmul(Q.T, Q)-np.eye(Q.shape[0]),'fro'))\n",
        "print(\"||QR-A||_F:\", np.linalg.norm(np.matmul(Q,R)-A,'fro'))\n",
        "\n",
        "print(\"\\n\")\n",
        "A = np.matrix([[2.,-2.,18],[2.,1.,0.],[1.,2.,0.]])\n",
        "print(\"A\",A)\n",
        "Q,R = qr_householder(A)\n",
        "print(\"Q\",Q)\n",
        "print(\"R\",R)\n",
        "print(\"QR\", np.matmul(Q,R))\n",
        "print(\"||(Q^TQ)-I||_F:\", np.linalg.norm(np.matmul(Q.T, Q)-np.eye(Q.shape[0]),'fro'))\n",
        "print(\"||QR-A||_F:\", np.linalg.norm(np.matmul(Q,R)-A,'fro'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A [[ 12. -51.   4.]\n",
            " [  6. 167. -68.]\n",
            " [ -4.  24. -41.]]\n",
            "Q [[ 0.85714286  0.39428571 -0.33142857]\n",
            " [ 0.42857143 -0.90285714  0.03428571]\n",
            " [-0.28571429 -0.17142857 -0.94285714]]\n",
            "R [[  14.   21.  -14.]\n",
            " [   0. -175.   70.]\n",
            " [   0.    0.   35.]]\n",
            "QR [[ 12. -51.   4.]\n",
            " [  6. 167. -68.]\n",
            " [ -4.  24. -41.]]\n",
            "||(Q^TQ)-I||_F: 2.1082954941545044e-16\n",
            "||QR-A||_F: 3.372739873350299e-14\n",
            "\n",
            "\n",
            "A [[ 2. -2. 18.]\n",
            " [ 2.  1.  0.]\n",
            " [ 1.  2.  0.]]\n",
            "Q [[ 0.66666667  0.66666667 -0.33333333]\n",
            " [ 0.66666667 -0.33333333  0.66666667]\n",
            " [ 0.33333333 -0.66666667 -0.66666667]]\n",
            "R [[ 3.00000000e+00  4.44089210e-16  1.20000000e+01]\n",
            " [-4.44089210e-16 -3.00000000e+00  1.20000000e+01]\n",
            " [-2.22044605e-16  4.44089210e-16 -6.00000000e+00]]\n",
            "QR [[ 2.00000000e+00 -2.00000000e+00  1.80000000e+01]\n",
            " [ 2.00000000e+00  1.00000000e+00 -4.73695157e-15]\n",
            " [ 1.00000000e+00  2.00000000e+00 -2.59052039e-15]]\n",
            "||(Q^TQ)-I||_F: 3.54480224075286e-16\n",
            "||QR-A||_F: 5.622694764690521e-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_ijs1XKM23l",
        "colab_type": "text"
      },
      "source": [
        "### Direct Solve Ax = b\n",
        "\n",
        "The algorithm works on square matrices as shown by the following test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DMPtBzsM3GN",
        "colab_type": "code",
        "outputId": "5bef7585-aeee-4f81-bebf-71cdd456f039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "A = np.matrix([[1.,1.,-1.],[1.,-1.,2.],[2.,1.,1.]])\n",
        "b = np.array([7.,3.,9.])\n",
        "print(\"A:\",A)\n",
        "print(\"b:\",b)\n",
        "x = direct_solve(A,b)\n",
        "A = np.matrix([[1.,1.,-1.],[1.,-1.,2.],[2.,1.,1.]])\n",
        "ks = np.array([6, -1, -2])\n",
        "b = np.array([7.,3.,9.])\n",
        "print(\"known solution y: \", ks)\n",
        "print(\"x:\",x)\n",
        "print(\"||Ax-b||:\", np.linalg.norm(np.matmul(A,x)-np.matrix(b)))\n",
        "print(\"||x-y||:\", np.linalg.norm(x-ks))\n",
        "\n",
        "print(\"\\n\")\n",
        "A = np.matrix([[0.,4.,1.],[1.,3.,-2.],[-1.,-2.,2.]])\n",
        "b = np.array([2.,1.,3.])\n",
        "print(\"A:\",A)\n",
        "print(\"b:\",b)\n",
        "x = direct_solve(A,b)\n",
        "A = np.matrix([[0.,4.,1.],[1.,3.,-2.],[-1.,-2.,2.]])\n",
        "b = np.array([2.,1.,3.])\n",
        "print(\"x:\",x)\n",
        "print(\"||Ax-b||:\", np.linalg.norm(np.matmul(A,x)-np.matrix(b)))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: [[ 1.  1. -1.]\n",
            " [ 1. -1.  2.]\n",
            " [ 2.  1.  1.]]\n",
            "b: [7. 3. 9.]\n",
            "known solution y:  [ 6 -1 -2]\n",
            "x: [ 6. -1. -2.]\n",
            "||Ax-b||: 0.0\n",
            "||x-y||: 0.0\n",
            "\n",
            "\n",
            "A: [[ 0.  4.  1.]\n",
            " [ 1.  3. -2.]\n",
            " [-1. -2.  2.]]\n",
            "b: [2. 1. 3.]\n",
            "x: [-39.   4. -14.]\n",
            "||Ax-b||: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe",
        "colab_type": "text"
      },
      "source": [
        "All methods have been implemented to a point that they work well. Unfortunately, due to illness, I did not have the time or energy to take it further and make sure the methods also work on matrices that are not square, which would have been a good addition, since I do have ideas on how to make this work. "
      ]
    }
  ]
}