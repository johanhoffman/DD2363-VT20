{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "litneet64_lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT20/blob/litneet64/Lab-2/litneet64_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 2: Matrix Factorization**\n",
        "**Pablo Aravena**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        " We are tasked with the implementation of the QR Decomposition, a direct solver for the equation $Ax = b$ and also for the sparse Matrix multiplication with a vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "# **About the code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pdll1Xc9WP0e",
        "outputId": "9dc997f2-bb48-4e20-b484-aac638339104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2019 Pablo Aravena (pjan2@kth.se)\n",
        "\n",
        "# Based on the template by Johan Hoffman (jhoffman@kth.se)\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xw7VlErAX7NS",
        "colab": {}
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "import unittest\n",
        "import random as rd\n",
        "from math import isclose"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fC7sWjPE2X9C"
      },
      "source": [
        "In this report we implemented 3 methods, one for an efficient multiplication between sparse matrices on $CSR$ format and vectors, another one for the $QR$ Decomposition, for which we chose the $Gram-Schmidt$ process to get it done, and lastly, a direct solver for the linear equation $Ax = b$, for which we re-used the $QR$ decomposition method used previously instead of going for another decomposition like the $LU$ for this task. \n",
        "\n",
        "The results are then showed after running regular tests taking advantage of some already implemented numpy methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WeFO9QMeUOAu"
      },
      "source": [
        "# **Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K8yzio7v2X9G"
      },
      "source": [
        "#### Sparse Matrix-Vector Product\n",
        "This method should recieve an array of the matrix in $CSR$ format, it follows the algorithm shown on the lecture notes as seen in $Algorithm$ $5.9$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wpmGIpV52khU",
        "colab": {}
      },
      "source": [
        "# method for the sparse matrix-vector product\n",
        "def sparseMatrixVectorProduct(A, x):\n",
        "    val, col_idx, row_ptr,  = A[0], A[1], A[2]\n",
        "    \n",
        "    # create result vector\n",
        "    b = np.zeros(x.shape[0])\n",
        "    \n",
        "    # every row index\n",
        "    for i in range(x.shape[0]):\n",
        "        # only take non-null elements\n",
        "        for j in range(row_ptr[i], row_ptr[i + 1]):\n",
        "            b[i] += val[j] * x[col_idx[j]]\n",
        "    \n",
        "    return b\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qGBVXNRa2X9L"
      },
      "source": [
        "#### QR Decomposition\n",
        "\n",
        "Following the algorithm found on the lecture notes ($Algorithm$ $5.3$), we implement the $QR$ Decomposition based on the Gram-Schmidt process with a slight modification related to making and using a copy of the $A$ matrix. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KB8MP7WX2X9N",
        "colab": {}
      },
      "source": [
        "# QR Factorization\n",
        "def factQR(A):\n",
        "    dim = A.shape[0]\n",
        "    \n",
        "    # create empty Q, R matrices\n",
        "    R = np.zeros((dim, dim))\n",
        "    Q = np.zeros((dim, dim))\n",
        "    \n",
        "    # we need this otherwise the A matrix would end up being modified\n",
        "    A_copy = np.copy(A)\n",
        "    \n",
        "    # Gram-Schmidt process\n",
        "    for i in range(dim):\n",
        "        R[i,i] = np.linalg.norm(A_copy[:,i])\n",
        "        Q[:,i] = A_copy[:,i] / R[i,i]\n",
        "        \n",
        "        for j in range(i+1, dim):\n",
        "            R[i,j] = np.dot(Q[:,i], A[:,j])\n",
        "            A_copy[:,j] -= R[i,j] * Q[:,i]\n",
        "            \n",
        "    return Q, R\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VJQ6ut_22X9R"
      },
      "source": [
        "#### Direct Solver for Ax = b\n",
        "  For this method we took advantage of the QR Decomposition:\n",
        "  \n",
        "\\begin{equation*}\n",
        "    A = QR \\implies A^{-1} = Q^{-1} R^{-1}\n",
        "\\end{equation*}\n",
        "\n",
        "And $Q^{-1} = Q^{T}$ as $Q$ is an orthonormal matrix. Then, to get the $R^{-1}$ matrix we can just invert $R$ using backwards substitution, as it is an upper-triangular matrix. Following the algorithm found on the lecture notes ($Algorithm$ $5.1$) and using the next formula:\n",
        "\n",
        "\\begin{equation*}\n",
        "    x_i = \\left( b_i - \\sum_{j = i+1}^n a_{ij}x_j \\right) \\cdot \\frac{1}{a_{ii}}\n",
        "\\end{equation*}\n",
        "\n",
        "We use backwards substitution on:\n",
        "\n",
        "\\begin{equation*}\n",
        "    Ax = b \\implies QRx = b \\implies Rx = Q^{-1}b\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SL0qNweV2X9T",
        "colab": {}
      },
      "source": [
        "# solve the linear system Ax = b using the QR decomposition\n",
        "def directSolver(A, b):\n",
        "    # get the number of rows for A and the Q and R matrices\n",
        "    dim = A.shape[0]\n",
        "    Q, R = factQR(A)\n",
        "    \n",
        "    # create sol vector\n",
        "    x = np.zeros((dim, 1))\n",
        "    \n",
        "    # get the inverse of Q transposing it and the new b vector\n",
        "    Q_inv = np.transpose(Q)\n",
        "    new_b = Q_inv @ b\n",
        "    \n",
        "    # backwards substitution to get x\n",
        "    x[dim - 1, 0] = new_b[dim - 1] / R[dim-1, dim-1]\n",
        "    \n",
        "    for i in reversed(range(dim-1)):\n",
        "        curr_sum = 0\n",
        "        for j in range(i+1, dim):\n",
        "            curr_sum += R[i,j] * x[j, 0]\n",
        "            \n",
        "        x[i, 0] = (new_b[i] - curr_sum) / R[i,i]\n",
        "        \n",
        "    return x\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jtUv3B0u2X9n"
      },
      "source": [
        "#### Tester class\n",
        "\n",
        "We implemented a class inheriting from the `unittest` framework as to run some test cases. These are bulk tests with randomized dimensions and elements for the matrices. The chosen number of test cases is $1.000$. \n",
        "\n",
        "For the Sparse Matrix-Vector multiplication, random square matrices were created, which where later transformed into sparse ones at random places (making some elements $0$) and also random vectors were made. Later, our multiplication result was tested against the numpy multiplication used for dense matrices.\n",
        "\n",
        "To test the $QR$ Decomposition, the residuals for $||QR - A||$ and $||Q^{-1}Q - I||$ were compared to $0$ (with an error tolerance within $10^{-10}$). A similar approach was taken with the direct solver residual, where $||Ax - b||$ was compared then to $0$, after getting our own result for $x$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E6ehOLuC2X9q",
        "colab": {}
      },
      "source": [
        "# matrix tester class\n",
        "class MatrixTester(unittest.TestCase):\n",
        "    # number of test cases and maximum number of rows/cols\n",
        "    TEST_CASES = 1000\n",
        "    MAX_ROWS = 10\n",
        "    \n",
        "    # sparse matrix multiplication tester\n",
        "    def testSparseMult(self):\n",
        "        # go through 1.000 test cases\n",
        "        for i in range(self.TEST_CASES):\n",
        "            # get random number of rows and cols\n",
        "            dims = rd.randint(2, self.MAX_ROWS)\n",
        "            \n",
        "            # generate random square matrix and vector\n",
        "            A = np.random.rand(dims, dims)*2\n",
        "            x = np.random.rand(dims, 1)[:,0]\n",
        "            \n",
        "            # and then make A a sparse matrix\n",
        "            for i in range(rd.randint(0, dims)):\n",
        "                for j in range(rd.randint(0, dims)):\n",
        "                    A[i, j] = 0\n",
        "            \n",
        "            # parse it from dense form to csr format\n",
        "            sparse_A = csr_matrix(A)\n",
        "            sparse_A = [sparse_A.data, sparse_A.indices, sparse_A.indptr]\n",
        "\n",
        "            our_b = sparseMatrixVectorProduct(sparse_A, x)\n",
        "            real_b = A @ x\n",
        "            \n",
        "            # test our b vector with corresponding real value given by numpy \n",
        "            # dense-matrix multiplication (error tolerance of 1e-05)\n",
        "            self.assertTrue(np.allclose(our_b, real_b))\n",
        "            \n",
        "    \n",
        "    # random bulk tester for the jacobi iteration method\n",
        "    def testQRDecomposition(self):\n",
        "        # 1.000 test cases\n",
        "        for i in range(self.TEST_CASES):\n",
        "            # random number of rows and cols\n",
        "            n = rd.randint(2, self.MAX_ROWS)\n",
        "            \n",
        "            # get random square matrix\n",
        "            A_matr = np.random.rand(n, n)*10\n",
        "\n",
        "            # get our Q and R matrices\n",
        "            Q,R = factQR(A_matr)\n",
        "            \n",
        "            # get the norm for (QR - A)\n",
        "            first_norm_test = np.linalg.norm(Q @ R - A_matr)\n",
        "\n",
        "            # get the inverse of Q (same as the transpose) and the Identity matrix\n",
        "            Q_inv = np.transpose(Q)\n",
        "            I = np.identity(n)\n",
        "            \n",
        "            # and get the norm of (Q^-1 Q - I)\n",
        "            sec_norm_test = np.linalg.norm(Q_inv @ Q - I)\n",
        "            \n",
        "            # test that ||QR - A|| = 0\n",
        "            self.assertTrue(isclose(first_norm_test, 0, abs_tol = 1e-10))\n",
        "            \n",
        "            # test that ||Q^-1 Q - I|| = 0\n",
        "            self.assertTrue(isclose(sec_norm_test, 0, abs_tol = 1e-10))\n",
        "            \n",
        "            \n",
        "    # tester for our direct solver for Ax = b\n",
        "    def testDirectSolver(self):\n",
        "        # 1.000 test cases\n",
        "        for i in range(self.TEST_CASES):\n",
        "            # random dimension for matrix A\n",
        "            n = rd.randint(2, self.MAX_ROWS)\n",
        "            \n",
        "            # get random square matrix and vector\n",
        "            A = np.random.rand(n, n)*10\n",
        "            b = np.random.rand(n, 1)*2\n",
        "            \n",
        "            # get our solution vector\n",
        "            x = directSolver(A, b)\n",
        "            \n",
        "            # get the norm of (Ax - b)\n",
        "            residual = np.linalg.norm(A @ x - b)\n",
        "            \n",
        "            # test that the residual is close to 0 ||Ax - b|| = 0\n",
        "            self.assertTrue(isclose(residual, 0, abs_tol = 1e-10))\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "The results shows that no errors were caused by the tests, proving they work as intended. As we were given multiple choices to implement the QR Decomposition and the Direct Solver this task proved to be an interesting one."
      ]
    }
  ]
}