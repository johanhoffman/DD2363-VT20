{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "felipevicencion-report-lab-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne205wrhj1m3",
        "colab_type": "text"
      },
      "source": [
        "# **Lab 2: Matrix Factorization**\n",
        "**Felipe Vicencio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOAn9nlrkAQ3",
        "colab_type": "text"
      },
      "source": [
        "# **Abstract**\n",
        "This report contains functions to factorize matrices, and a function for sparse-matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMkbEm2RkhEL",
        "colab_type": "text"
      },
      "source": [
        "# **About the code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmtaQ4qwkwI2",
        "colab_type": "code",
        "outputId": "21cf21ab-4b84-49e0-f101-1efaa44b28a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Author: Felipe Vicencio Neumann\n",
        "# Date: 10-2-2020\n",
        "\n",
        "# Based on a template by Johan Hoffman:\n",
        "# Copyright (C) 2019 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbnjTZlUlTUZ",
        "colab_type": "text"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5BzSUnlaqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import random as r\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmD2p7WAmEVx",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "In this lab 3: sparce-matrix multiplication, QR factorization, and Direct $Ax = b$ solver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eGnlxHonPdm",
        "colab_type": "text"
      },
      "source": [
        "# **Methods**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRX_yuzBoKfY",
        "colab_type": "text"
      },
      "source": [
        "## Sparse-Matrix Multiplication:\n",
        "Sparse Matrices are a way to store matrices using less memory than they'd normally need, by storing only the non-zero values using 3 lists:\n",
        "- **val**: stores all the non-zero values in order\n",
        "- **column_index**: stores the column index of each non-zero value\n",
        "- **row_pointer**: starts with a 0, and then for each row is stores the number of non-zero values, plus the number of non-zero values in the rows that came before\n",
        "\n",
        "In order to take a row from the matrix, we define **row_start** and **row_end**, which corresponds to **row_index[row_number]** and **row_index[row_number + 1]** respectively. Then, the values in the row are **val[row_start : row_end]** and their correspoindg column values are **column_indes[row_start : row_end]**.\n",
        "\n",
        "By doing this, not only do we avoid storing the zero values, but also multiplying them, since we can use de column indexes to only take the values we need to multiply.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHpBdJgGntrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_mult(val, col_idx, row_ptr, x):\n",
        "\tb = np.zeros(row_ptr.size - 1)\n",
        "\tfor row in range(row_ptr.size-1):\n",
        "\t\t\trow_start, row_end = row_ptr[row], row_ptr[row+1]\n",
        "\t\t\trow_values = val[row_start:row_end]\n",
        "\t\t\tcolumns = col_idx[row_start:row_end]\n",
        "\t\t\tnew_value = 0\n",
        "\t\t\tfor i in range(columns.size):\n",
        "\t\t\t\tnew_value += row_values[i]*x[columns[i]]\n",
        "\t\t\tb[row] = new_value\n",
        "\treturn b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvx9O5CUo8v4",
        "colab_type": "text"
      },
      "source": [
        "## QR Factorization:\n",
        "QR factorization is a method to decompose a matrix into a product of an orthogonal matrix (Q), and an upper-triangular matrix (R).\n",
        "\n",
        "To do this, we first define the projection:\n",
        "\n",
        "$proj_u(a )= \\frac{\\langle u, a\\rangle}{\\langle u, u\\rangle}u$\n",
        "\n",
        "then, we take columns:\n",
        "\n",
        "$u_k = a_k - \\sum_{i+1}^{k-1}proj_{u_i}(a_k)$\n",
        "\n",
        "where $a_i$ correspond to the columns of the full column rank matrix $A = [a_1, ..., a_n]$.\n",
        "\n",
        "Then, to get Q, we divide each $u_k$ column by its norm:\n",
        "\n",
        "$Q = \\Big( \\frac{u_1}{||u_1||} \\quad \\frac{u_1}{||u_1||} \\quad \\cdots \\quad \\frac{u_n}{||u_n||}\\Big)$\n",
        "\n",
        "After this, it's easy to get $R$:\n",
        "\n",
        "$Q^TQ = I\\\\\n",
        "Q^TA = Q^TQR = R$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emIDLoJ1tClr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def proj(u, a):\n",
        "  assert(u.ndim == a.ndim == 1)\n",
        "  if abs(np.dot(u,u)) < 0.0001:\n",
        "    return \"error\"\n",
        "  frac = np.dot(u,a)/np.dot(u, u)\n",
        "  return frac*u\n",
        "\n",
        "def QR(A):\n",
        "  rows, cols = A.shape\n",
        "  t = np.transpose(A)   #we transpose the matrix to make it easier to take the columns\n",
        "  Q = np.zeros(t.shape) #This Q corresponds to Q^t\n",
        "  Q[0] = t[0] \n",
        "  for col_num in range(1, cols):\n",
        "    u = t[col_num]\n",
        "    for i in range(col_num):\n",
        "      p =  proj(Q[i], t[col_num])\n",
        "      if type(p) == str:\n",
        "        return(\"###Error, matrix A is linearly dependent\")\n",
        "      else:\n",
        "        u = u - p\n",
        "    Q[col_num] = u\n",
        "  for i in range(Q.shape[0]):\n",
        "    Q[i] = Q[i]/np.linalg.norm(Q[i])\n",
        "  return(np.transpose(Q), Q@A)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfmLD9LYtj1I",
        "colab_type": "text"
      },
      "source": [
        "## Direct Solve:\n",
        "We can use backwards substitution and QR factorization to solve $Ax = b$:\n",
        "\n",
        "$Ax = b \\\\ Q^TAx = Q^Tb \\\\ Rx = Q^Tb$\n",
        "\n",
        "And then we use backwards substitution with the matrix $R$ and the vector $Q^Tb$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-2JE3r-xDFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_sub(A, b):\n",
        "\t\tx = [b[-1]/A[-1][-1]]\n",
        "\t\tfor row in reversed(range(A.shape[0]-1)):\n",
        "\t\t\ts = 0\n",
        "\t\t\tfor i in range(len(x)):\n",
        "\t\t\t\ts += x[-1 - i] * A[row][-1 - i]\n",
        "\t\t\tx.insert(0, (b[row] - s)/A[row][row])\n",
        "\t\treturn x\n",
        "\n",
        "def direct_solve(A, b):\n",
        "    Q, R = QR(A)\n",
        "    Qt = np.transpose(Q)\n",
        "    return back_sub(R, Qt@b)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fErb3m4cyrSh",
        "colab_type": "text"
      },
      "source": [
        "# **Results**\n",
        "The methods were tested in the following ways:\n",
        "\n",
        "- **Sparse-matrix Multiplication**: tested against numpy multiplying the normal matrix\n",
        "- **QR Factorization**: tested against Frobenius norms (square root of the sum of all elements of the matrix squared)\n",
        "- **Direct Solve**: tested against np.solve()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2NUO7s0TS9",
        "colab_type": "code",
        "outputId": "ed2bb65a-cd23-4de8-acc7-cdc8b576c60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Sparse-Matrix multiplication tests:\n",
        "\n",
        "A         = np.array([[0,0,0,0], [5,8,0,0], [0,0,3,0], [0,6,0,0]])\n",
        "VAL       = np.array([5, 8, 3, 6])\n",
        "COL_INDEX = np.array([0,1,2,1])\n",
        "ROW_INDEX = np.array([0,0,2,3,4])\n",
        "x         = np.array([2, 5, 2, 3])\n",
        "assert(np.array_equal(sparse_mult(VAL, COL_INDEX, ROW_INDEX, x), A@x))\n",
        "\n",
        "A         = np.array([[10, 20, 0, 0, 0, 0], [0, 30, 0, 40, 0, 0], [0, 0, 50, 60, 70, 0], [0, 0, 0, 0, 0, 80]])\n",
        "VAL       = np.array([10, 20, 30, 40, 50, 60, 70, 80])\n",
        "COL_INDEX = np.array([0, 1, 1, 3, 2, 3, 4, 5])\n",
        "ROW_INDEX = np.array([0, 2, 4, 7, 8])\n",
        "x         = np.array([1, 6, 3, 2, 11, 8])\n",
        "assert(np.array_equal(sparse_mult(VAL, COL_INDEX, ROW_INDEX, x), A@x))\n",
        "\n",
        "A         = np.array([[7, 7, 6, 1], [8, 8, 6, 7], [4, 2, 5, 12]])\n",
        "VAL       = np.array([7, 7, 6, 1, 8, 8, 6, 7, 4, 2, 5, 12])\n",
        "COL_INDEX = np.array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])\n",
        "ROW_INDEX = np.array([0, 4, 8, 12])\n",
        "x         = np.array([3, 4, 1, 5])\n",
        "assert(np.array_equal(sparse_mult(VAL, COL_INDEX, ROW_INDEX, x), A@x))\n",
        "\n",
        "print(\"Sparse-Matrix multiplication test passed\")\n",
        "\n",
        "\n",
        "# QR Factorization tests:\n",
        "\n",
        "A = np.array([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])\n",
        "Q, R = QR(A) \n",
        "assert(np.linalg.norm(Q@R - A) < 10**(-6))\n",
        "assert(np.linalg.norm(np.transpose(Q)@Q - np.identity(A.shape[0]) < 10**(-6)))\n",
        "\n",
        "A = np.array([[1, 2, 3, 4], [5, 2.3, 7, 8], [-1, -2, 0, -4], [0.2, 0, -1, -0.3]])\n",
        "Q, R = QR(A) \n",
        "assert(np.linalg.norm(Q@R - A) < 10**(-6))\n",
        "assert(np.linalg.norm(np.transpose(Q)@Q - np.identity(A.shape[0]) < 10**(-6)))\n",
        "\n",
        "A = np.array([[0, 1, 0], [0, 1, 0], [0, 2, 0]])\n",
        "print(QR(A)) #Should throw an error, since A is linearly dependent\n",
        "\n",
        "print(\"QR Factirization test passed\")\n",
        "\n",
        "\n",
        "# Direct Solve tests:\n",
        "\n",
        "A = np.array([[1, -2, 1],[0, 1, 6],[0, 0, 1]])\n",
        "b = np.array([4, -1, 2])\n",
        "x = direct_solve(A, b)\n",
        "assert(np.linalg.norm(A@x - b) < 10**(-6))\n",
        "assert(np.linalg.norm(x - np.linalg.solve(A, b)) < 10**(-6))\n",
        "\n",
        "A = np.array([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])\n",
        "b = np.array([1, -1, 2])\n",
        "x = direct_solve(A, b)\n",
        "assert(np.linalg.norm(A@x - b) < 10**(-6))\n",
        "assert(np.linalg.norm(x - np.linalg.solve(A, b)) < 10**(-6))\n",
        "\n",
        "A = np.array([[1, 2, 3, 4], [5, 2.3, 7, 8], [-1, -2, 0, -4], [0.2, 0, -1, -0.3]])\n",
        "b = np.array([3, -4, -8, 0])\n",
        "x = direct_solve(A, b)\n",
        "assert(np.linalg.norm(A@x - b) < 10**(-6))\n",
        "assert(np.linalg.norm(x - np.linalg.solve(A, b)) < 10**(-6))\n",
        "\n",
        "print(\"Direct Solve test passed\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparse-Matrix multiplication test passed\n",
            "###Error, matrix A is linearly dependent\n",
            "QR Factirization test passed\n",
            "Direct Solve test passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nof5gy0n2Hk_",
        "colab_type": "text"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "As expected, the functions give the desired results. It's worth noting that Sparse-Matrices should probably be used in the QR algorithm if we want to use it on bigger matrices, since R will always contain many zeros. By doing this, the Direct Solve algorithm could alse a little more optimized.\n",
        "Some parts of this report were made in collaboration with FabiÃ¡n Levican."
      ]
    }
  ]
}