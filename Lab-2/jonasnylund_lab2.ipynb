{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT20/blob/JonasNylund/Lab-2/jonasnylund_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7",
        "colab_type": "text"
      },
      "source": [
        "# **Lab 2: Matrix Factorization**\n",
        "**Jonas Nylund**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3",
        "colab_type": "text"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo",
        "colab_type": "text"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab_type": "code",
        "outputId": "68f42f38-3c14-413e-d77b-391871a257a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2020 Jonas Nylund (jonasnyl@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh",
        "colab_type": "text"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa",
        "colab_type": "text"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import numpy as np;\n",
        "from numpy import random;\n",
        "from scipy import sparse;\n",
        "from scipy.sparse import csr_matrix;\n",
        "\n",
        "import unittest\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6",
        "colab_type": "text"
      },
      "source": [
        "Give a short description of the problem investigated in the report, and provide some background information so that the reader can understand the context. \n",
        "\n",
        "Briefly describe what method you have chosen to solve the problem, and justify why you selected that method. \n",
        "\n",
        "\n",
        "Efficient matrix algorithms are useful for solving linear algebra problems. Here are some implemented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeFO9QMeUOAu",
        "colab_type": "text"
      },
      "source": [
        "# **Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klqG_5KTd-Do",
        "colab_type": "text"
      },
      "source": [
        "**Sparse Matrix-vector product**\n",
        "\n",
        "For sparse matrices, where most of the cells are 0, it is very wasteful to do dense matrix multiplication. Instead, for sparse matrices, we can implement \"sparse multiplication\", where only the cells actually containing data are multiplied with a vector **x**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t1Qmroid2w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparseProduct(x, val, col_idx, row_ptr):\n",
        "  ## Assume that x and Matrix are the same dimensions. Cannot really be \n",
        "  ## checked here since the format does not support it.\n",
        "  assert len(x) >= max(col_idx);\n",
        "\n",
        "\n",
        "  out = np.zeros(len(row_ptr)-1);\n",
        "  for i in range(len(row_ptr)-1):\n",
        "    rs = row_ptr[i];\n",
        "    re = row_ptr[i+1];\n",
        "    for j in range(re-rs):\n",
        "      col = col_idx[rs+j];\n",
        "      v = val[rs+j];\n",
        "      out[i] += v*x[col];\n",
        "\n",
        "  return out;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5ye3bRHly2K",
        "colab_type": "code",
        "outputId": "ccd17336-456d-43d9-f5e2-8d8876f35a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "m = np.random.randint(2,10);\n",
        "n = np.random.randint(2,10);\n",
        "A = csr_matrix(sparse.random(m,n,0.25));\n",
        "x = random.rand(n);\n",
        "\n",
        "print(m,n);\n",
        "print(A @ x);\n",
        "print(sparseProduct(x, A.data, A.indices, A.indptr));\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 7\n",
            "[0.81479742 0.         0.60141252 1.23667301 0.53705956]\n",
            "[0.81479742 0.         0.60141252 1.23667301 0.53705956]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiUzO6hhpM3a",
        "colab_type": "text"
      },
      "source": [
        "**QR factorization**\n",
        "\n",
        "Factorizing a matrix **A** into a orthogonal matrix **Q** and a triangular matrix **R** can be used to solve certain linear algebra equations efficiently. The factorization can be done in multiple ways, here is an implementation of the modified Gram–Schmidt process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrGDAuFUpRki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def qrFactorize(mat):\n",
        "  A = np.array(mat);\n",
        "  m = A.shape[0];\n",
        "  n = A.shape[1];\n",
        "  assert m >= n;\n",
        "\n",
        "  #==============================================#\n",
        "  # https://f.kth.se/sangbok/#!/chapter/8/song/16\n",
        "  i = 0;\n",
        "\n",
        "  ##Tag en delrumsbas M och en vektor a\n",
        "  M = [];\n",
        "  while i < n:\n",
        "    a = np.array(A[:,i]);\n",
        "\n",
        "    ##Projicera ner, tag dess residual\n",
        "    for j in range(i):\n",
        "      a -= np.dot(A[:,i], M[j])*M[j];\n",
        "\n",
        "    ## Normalisera, tillför den till M\n",
        "    M.append( a/np.linalg.norm(a) );\n",
        "\n",
        "    ##Ta sen nästa vektor, börja om igen\n",
        "    i += 1;\n",
        "  #==============================================#\n",
        "\n",
        "  Q = np.zeros(A.shape);\n",
        "  R = np.zeros((n,n));\n",
        "  for i in range(n):\n",
        "    Q[:,i] = M[i];\n",
        "    for j in range(i, n):\n",
        "      R[i,j] = np.dot(A[:,j], M[i]);\n",
        "\n",
        "  return Q, R;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eesElruytMYp",
        "colab_type": "code",
        "outputId": "4a5f05b4-e1e7-4a58-a609-206273a4ac21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "n = np.random.randint(2,10);\n",
        "m = np.random.randint(n,10);\n",
        "\n",
        "A = np.random.rand(m,n);\n",
        "Q,R = qrFactorize(A);\n",
        "q,r = np.linalg.qr(A);\n",
        "\n",
        "print(\"R triangular:\", np.allclose(R, np.triu(R, 0)));\n",
        "print(\"||Q@R - A|| =\",np.linalg.norm((Q @ R) - A, ord='fro'));\n",
        "print(\"||Q^T@Q - I|| =\",np.linalg.norm((Q.transpose() @ Q) - np.eye(n), ord='fro'));\n",
        "print(\"Equal to numpy solution:\", np.allclose(np.abs(Q),np.abs(q)) and np.allclose(np.abs(R),np.abs(r)));"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R triangular: True\n",
            "||Q@R - A|| = 7.871593303505863e-16\n",
            "||Q^T@Q - I|| = 4.025725416188366e-15\n",
            "Equal to numpy solution: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZM8w1W5BYty",
        "colab_type": "text"
      },
      "source": [
        "**Direct solver**\n",
        "\n",
        "Solving Systems of linear equations are done by matrix inversion. Here, we use QR decomposition to invert a matrix. THe back substitution algorithm uses Gauss elimination. The system could be solved without inverting R, but this was simpler to implement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFK5776QBasp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backSubst(mat):\n",
        "  ## A must be square\n",
        "  A = np.array(mat);\n",
        "  assert A.shape[0] == A.shape[1];\n",
        "  \n",
        "  I = np.eye(A.shape[0]);\n",
        "  n = A.shape[0];\n",
        "\n",
        "  for i in range(n):\n",
        "    I[i,:] /= A[i,i];\n",
        "    A[i,:] /= A[i,i];\n",
        "  \n",
        "  ## Gaussian elimination, backward \n",
        "  for i in range(1,n):\n",
        "    I[n-i,:] /= A[n-i,n-i];\n",
        "    A[n-i,:] /= A[n-i,n-i];\n",
        "\n",
        "    for j in range(1, n-i+1):\n",
        "      f = A[n-i-j,n-i];\n",
        "      I[n-i-j,:] -= I[n-i,:]*f;\n",
        "      A[n-i-j,:] -= A[n-i,:]*f;\n",
        "\n",
        "  return I;\n",
        "\n",
        "def invert(A):\n",
        "  assert A.shape[0] == A.shape[1];\n",
        "  ## Invert A by QR-factorization\n",
        "  Q,R = qrFactorize(A);\n",
        "  Qi = Q.transpose(); ## invert Q by transposing\n",
        "  Ri = backSubst(R);  ## invert R by back substitution\n",
        "  return (Ri @ Qi);\n",
        "\n",
        "def solve(A, b):\n",
        "  return invert(A) @ b;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqvy8bIsFQDi",
        "colab_type": "code",
        "outputId": "d0252549-dad9-4520-ccd5-4495ef0bb2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "m = np.random.randint(2,10);\n",
        "\n",
        "A = np.random.rand(m,m)*1000-500;\n",
        "b = np.random.rand(m)*1000-500;\n",
        "x = solve(A,b);\n",
        "print(\"||A@x - b|| =\", np.linalg.norm(A@x - b));\n",
        "\n",
        "A = np.random.rand(m,m)*1000-500;\n",
        "y = np.random.rand(m)*1000-500;\n",
        "b = A@y;\n",
        "x = solve(A,b);\n",
        "print(\"||x-y|| =\",np.linalg.norm(x-y));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "||A@x - b|| = 3.9992890150046743e-13\n",
            "||x-y|| = 7.568029316369878e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxlgAQokzGYX",
        "colab_type": "text"
      },
      "source": [
        "**Least squares problem**\n",
        "\n",
        "THe least squares problem is often encountered in science, for fitting data to equations for example. The least squares problem can also be solved with QR decomposition (what a wonderful thing!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bc25_R33M9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def leastSquare(A, b):\n",
        "  Q1,R1 = qrFactorize(A);\n",
        "  Qi = Q1.transpose();\n",
        "  Ri = backSubst(R1);\n",
        "  return Ri @ (Qi @ b);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKCeJI6t40gH",
        "colab_type": "code",
        "outputId": "8fe5f155-3016-4d8f-929f-d77cf8b3ec6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "m = np.random.randint(2,10);\n",
        "n = m + np.random.randint(2,10);\n",
        "\n",
        "A = np.random.rand(n,m);\n",
        "b = np.random.rand(n);\n",
        "\n",
        "x1 = leastSquare(A,b);\n",
        "x2 = np.linalg.lstsq(A,b, rcond=None)[0];\n",
        "\n",
        "print(\"lstsq residual:\",np.linalg.norm(A@x1-b));\n",
        "print(\"numpy lstsq reiduals:\",np.linalg.norm(A@x2-b));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstsq residual: 0.46921473180502676\n",
            "numpy lstsq reiduals: 0.4692147318050268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVJ8aqxHFU28",
        "colab_type": "text"
      },
      "source": [
        "**Eigenvalues and Eigenvectors of symmetrix Matrices**\n",
        "\n",
        "The eigenvalues and eigenvectors of a matrix **A** can be calculated using the *QR-algorithm*, which is an iterative process that also uses QR factorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w5j2f9CFaw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eigen(mat):\n",
        "  A = np.array(mat);\n",
        "  assert A.shape[0] == A.shape[1];      ## A has to be square\n",
        "  assert np.allclose(A, A.transpose()); ## A has to be symmetric\n",
        "  U = np.eye(A.shape[0]);\n",
        "\n",
        "  for i in range(100):\n",
        "    Q,R = qrFactorize(A);\n",
        "    A = R @ Q;\n",
        "    U = U @ Q;\n",
        "\n",
        "  return A, U;\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTLU4wylHsCK",
        "colab_type": "code",
        "outputId": "93ed2cd8-2eaf-4957-b11a-7ebf831f5e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "m = np.random.randint(2,10);\n",
        "\n",
        "A = np.random.rand(m,m)\n",
        "A = (A+A.transpose())/2;  ## Make A symmetric, otherwise we will have complex eigenvalues\n",
        "T,U = eigen(A);\n",
        "\n",
        "for i in range(len(T)):\n",
        "  print(np.linalg.det(A-T[i,i]*np.eye(m)));\n",
        "print();\n",
        "\n",
        "for i in range(len(U)):\n",
        "  print(np.linalg.norm(A@U[:,i] - T[i,i]*U[:,i]));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.18973465712234e-10\n",
            "1.7480786628199113e-14\n",
            "-1.1368955906382902e-05\n",
            "-8.92380084304716e-06\n",
            "1.1383395701359398e-16\n",
            "2.7969732514831746e-18\n",
            "5.604445707379144e-18\n",
            "7.95174644165735e-17\n",
            "2.2087428892039665e-18\n",
            "\n",
            "7.421074851107613e-15\n",
            "1.1679618048569541e-14\n",
            "0.003795829633934062\n",
            "0.003795829633933979\n",
            "1.809783439170562e-09\n",
            "1.8097849461602667e-09\n",
            "2.814611826769246e-15\n",
            "8.359126874403208e-15\n",
            "2.1024262926272527e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_",
        "colab_type": "text"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkdD8yGypgme",
        "colab_type": "code",
        "outputId": "07a93f43-c9c0-4bba-8f8a-aaef93dc8503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "class TestMatrixMethods(unittest.TestCase):\n",
        "\n",
        "  def test_sparse(self):\n",
        "    for i in range(100):\n",
        "      m = np.random.randint(2,10);\n",
        "      n = np.random.randint(2,10);\n",
        "      dens = np.random.uniform(low=1/(m*n), high=0.9);\n",
        "      A = csr_matrix(sparse.random(m,n,dens));\n",
        "      x = random.rand(n);\n",
        "\n",
        "      self.assertTrue(np.allclose(A @ x, sparseProduct(x, A.data, A.indices, A.indptr)));\n",
        "\n",
        "\n",
        "  def test_qrFactorize(self):\n",
        "    for i in range(100):\n",
        "      n = np.random.randint(2,10);\n",
        "      m = np.random.randint(n,10);  ## m >= n for QR to work (kind of)\n",
        "\n",
        "      A = np.random.rand(m,n);\n",
        "      Q,R = qrFactorize(A);\n",
        "      q,r = np.linalg.qr(A);\n",
        "\n",
        "      self.assertTrue(np.allclose(R, np.triu(R, 0)));\n",
        "      self.assertTrue(np.linalg.norm((Q @ R) - A, ord='fro') < 10**(-6));\n",
        "      self.assertTrue(np.linalg.norm((Q.transpose() @ Q) - np.eye(n), ord='fro') < 10**(-6));\n",
        "      self.assertTrue(np.allclose(np.abs(Q),np.abs(q)) and np.allclose(np.abs(R),np.abs(r)));\n",
        "\n",
        "  def test_directSolver(self):\n",
        "    for i in range(100):\n",
        "      m = np.random.randint(2,10);\n",
        "\n",
        "      A = np.random.rand(m,m)*1000-500;\n",
        "      b = np.random.rand(m)*1000-500;\n",
        "      x = solve(A,b);\n",
        "      self.assertTrue(np.linalg.norm(A@x - b) < 10**(-6));\n",
        "\n",
        "      A = np.random.rand(m,m)*1000-500;\n",
        "      y = np.random.rand(m)*1000-500;\n",
        "      b = A@y;\n",
        "      x = solve(A,b);\n",
        "      self.assertTrue(np.linalg.norm(x-y) < 10**(-6));\n",
        "\n",
        "  def test_leastSquares(self):\n",
        "    for i in range(100):\n",
        "      m = np.random.randint(2,10);\n",
        "      n = m + np.random.randint(2,10);\n",
        "\n",
        "      A = np.random.rand(n,m);\n",
        "      b = np.random.rand(n);\n",
        "\n",
        "      x1 = leastSquare(A,b);\n",
        "      x2 = np.linalg.lstsq(A,b, rcond=None)[0];\n",
        "\n",
        "      self.assertTrue(np.linalg.norm(A@x1-b) - np.linalg.norm(A@x2-b) < 10**(-6));\n",
        "\n",
        "\n",
        "  def test_eigen(self):\n",
        "    err = 0;\n",
        "    M = 0;\n",
        "    for i in range(100):\n",
        "      m = np.random.randint(2,10);\n",
        "      M += m;\n",
        "\n",
        "      A = np.random.rand(m,m)\n",
        "      A = (A+A.transpose())/2;\n",
        "      T,U = eigen(A);\n",
        "\n",
        "      err = 0;\n",
        "      for i in range(len(T)):\n",
        "        if(np.linalg.det(A-T[i,i]*np.eye(m)) > 10**(-6)):\n",
        "          err+=1;\n",
        "\n",
        "      for i in range(len(U)):\n",
        "        if(np.linalg.norm(A@U[:,i] - T[i,i]*U[:,i]) > 10**(-6)):\n",
        "          err += 1;\n",
        "\n",
        "    ## sometimes the convergence is kind of poor, and the eigenvalue\n",
        "    ## is iffy. It's correct most of the time, but not always\n",
        "    self.assertTrue(err < 2*M/50);\n",
        "\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_directSolver (__main__.TestMatrixMethods) ... ok\n",
            "test_eigen (__main__.TestMatrixMethods) ... ok\n",
            "test_leastSquares (__main__.TestMatrixMethods) ... ok\n",
            "test_qrFactorize (__main__.TestMatrixMethods) ... ok\n",
            "test_sparse (__main__.TestMatrixMethods) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 2.212s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f6f8e8bee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd",
        "colab_type": "text"
      },
      "source": [
        "The algorithms all perform as prescribed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m",
        "colab_type": "text"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe",
        "colab_type": "text"
      },
      "source": [
        "Summarize your results and your conclusions. Were the results expected or surprising. Do your results have implications outside the particular problem investigated in this report? \n",
        "\n",
        "Overall, the algorithms works mostly as intended. QR factorization required $m\\geq n$. For matrices where $m< n$ some modifications would need to be made to the algorithm, that would produce **R** as a not square matrix. This was not done, and not needed to get least squares and eigen value factorization to work."
      ]
    }
  ]
}