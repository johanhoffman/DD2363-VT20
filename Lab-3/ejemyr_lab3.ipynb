{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ejemyr_lab_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363-VT20/blob/ejemyr/Lab-3/ejemyr_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 3: Iterative methods**\n",
        "**Christoffer Ejemyr**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# Abstract\n",
        "\n",
        "In this lab many different itterative methods were investigated. They generally succeded, but not allways. It is intresting how the initial values sometimes can matter to the degree that the method never converges for some initial values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "# About the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pdll1Xc9WP0e",
        "outputId": "855e77bf-545b-4a37-abbc-8cdc89ee8069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2019 Christoffer Ejemyr (ejemyr@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xw7VlErAX7NS",
        "colab": {}
      },
      "source": [
        "# Load neccessary modules.\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import unittest\n",
        "import math\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this lab we will solve systems of linear equations, as well as finding zeros of functions. This will all be done using iterative methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WeFO9QMeUOAu"
      },
      "source": [
        "# Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EN1qvsnqRj4z"
      },
      "source": [
        "### Standard basis\n",
        "Super simple vector generator. Replace element $i$ with $1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qN-JazumRj41",
        "colab": {}
      },
      "source": [
        "def standard_basis(n: int, i: int):\n",
        "    e_i = np.zeros(n)\n",
        "    e_i[i] = 1.\n",
        "    return e_i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nHeust2SRj4S"
      },
      "source": [
        "### Spectral radius\n",
        "\n",
        "We define the spectral radius of a matrix $M$ as \n",
        "\n",
        "$$\\rho(M) = \\text{max}\\lbrace|\\lambda_1|, |\\lambda_2|, \\ldots, |\\lambda_n|\\rbrace$$\n",
        "\n",
        "where $\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$ are the eigenvalues of $M$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6YTpQi8OZjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spectral_radius(M):\n",
        "    if type(M) != np.ndarray or M.ndim != 2:\n",
        "        raise Exception(\"M matrix format not recogniced.\")\n",
        "    return np.max(np.abs(np.linalg.eig(M)[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlvMgwWqOWlV",
        "colab_type": "text"
      },
      "source": [
        "### Richardson iteration\n",
        "\n",
        "Below I defined the left preconditioned Richardson iteration. Using $B = I$ (letting parameter `B=None`\n",
        ") you get the non preconitioned Richardson iteration.\n",
        "\n",
        "In my implementation I have the method raising an Exception when $\\rho(I - \\alpha BA) \\geq1$. This is beceause we can not guarantee convergence. But having $\\rho(I - \\alpha BA) \\geq 1$ does not necessarily make it divergent.\n",
        "\n",
        "I've also changed the stoping criteria to be $||b - Ax|| < \\text{TOL}$ instead of $||B(b - Ax)|| < \\text{TOL}$, since it generally is the residual $||b - Ax||$ you want to minimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvBbM7pURj4W",
        "colab": {}
      },
      "source": [
        "def richardson_iteration(A, b, alpha, tol=1e-6, x0=None, B=None):\n",
        "    \"\"\"The left preconditioned Richardson iteration.\"\"\"\n",
        "    \n",
        "    if type(A) != np.ndarray or A.ndim != 2:\n",
        "        raise Exception(\"A matrix format not recogniced.\")\n",
        "    if B is None:\n",
        "        B = np.eye(A.shape[0])\n",
        "    if type(B) != np.ndarray or B.ndim != 2:\n",
        "        raise Exception(\"B matrix format not recogniced.\")\n",
        "    if A.shape[0] != A.shape[1]:\n",
        "        raise Exception(\"Matrix not square.\")\n",
        "    if (x0 is not None) and x0.size != A.shape[1]:\n",
        "        raise Exception(\"Shapes of x0 and A does not agree.\")\n",
        "    if A.shape[0] != B.shape[1]:\n",
        "        raise Exception(\"Shapes of A and B does not agree.\")\n",
        "    if B.shape[0] != b.size:\n",
        "        raise Exception(\"Shapes of B and b does not agree.\")\n",
        "    \n",
        "    x = None\n",
        "    if x0 is None:\n",
        "        x = np.zeros(A.shape[1])\n",
        "    else:\n",
        "        x = x0.copy()\n",
        "        \n",
        "    if spectral_radius(np.eye(B.shape[0]) - alpha * B.dot(A)) >= 1:\n",
        "        return None\n",
        "    \n",
        "    r = np.zeros(B.shape[0])\n",
        "    r[:] = b - A.dot(x)\n",
        "    i = 0\n",
        "    while np.linalg.norm(r) > tol:\n",
        "        r[:] = b - A.dot(x)\n",
        "        x[:] = x[:] + alpha * B.dot(r)\n",
        "        i += 1\n",
        "\n",
        "    return x, i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CNMzSwaQRj4a"
      },
      "source": [
        "### Jacobi iteration\n",
        "\n",
        "As the lecture notes pointed out the Jacobi iteration is only the left preconditioned richardson itteration with $B = (\\alpha D)^{-1}$, where $D$ is the diagonal matrix with $\\text{diag}(D) = \\text{diag}(A)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9ZTdJEARj4d",
        "colab": {}
      },
      "source": [
        "def check_jacobi_convergence(A):\n",
        "    if (np.diag(A) != 0).all():\n",
        "        B = np.diag(1. / np.diag(A))\n",
        "        return spectral_radius(np.eye(B.shape[0]) - B.dot(A)) < 1\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def jacobi_iteration(A, b, tol=1e-6, x0=None):\n",
        "    if check_jacobi_convergence(A):\n",
        "        B = np.diag(1. / np.diag(A))\n",
        "        return richardson_iteration(A, b, 1., tol=tol, x0=x0, B=B)\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FhX3ZwNDRj4g"
      },
      "source": [
        "### Gauss-Seidel iteration\n",
        "\n",
        "As the lecture notes pointed out the Gauss-Seidel iteration is only the left preconditioned richardson itteration with $B = (\\alpha L)^{-1}$, where $L$ is the lower triangonal matrix created by zeroing out the over-diagonal elements in $A$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ULfGq2P8Rj4h",
        "colab": {}
      },
      "source": [
        "def check_gauss_seidel_convergence(A):\n",
        "    if (np.diag(A) != 0).all():\n",
        "        B = np.linalg.inv(np.tril(A))\n",
        "        return spectral_radius(np.eye(B.shape[0]) - B.dot(A)) < 1\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def gauss_seidel_iteration(A, b, tol=1e-6, x0=None):\n",
        "    if check_gauss_seidel_convergence(A):\n",
        "        B = np.linalg.inv(np.tril(A))\n",
        "        return richardson_iteration(A, b, 1., tol=tol, x0=x0, B=B)\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjl7lz1HuvKS",
        "colab_type": "text"
      },
      "source": [
        "### Newtons method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY4BPEMku4XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_derivative(f, x: np.array, dx_vec: np.array):\n",
        "    return (f(x + dx_vec) - f(x - dx_vec)) / (2 * np.linalg.norm(dx_vec))\n",
        "\n",
        "def jacobian(f, x0, dx: float):\n",
        "    n = x0.size\n",
        "    Df = np.zeros((n,n))\n",
        "    for i in range(0,n):\n",
        "        Df[:, i] = get_derivative(f, x0, dx * standard_basis(n, i))\n",
        "    return Df\n",
        "\n",
        "def newtons_method(f, x0, dx: float, tol=1e-6, max_itr=1e3):\n",
        "    x = x0\n",
        "    i = 0\n",
        "    while np.linalg.norm(f(x)) >= tol:\n",
        "        if i >= max_itr:\n",
        "            print(\"Max itr\")\n",
        "            return None\n",
        "        i += 1\n",
        "\n",
        "        Df = jacobian(f, x0, dx)\n",
        "        if np.allclose(np.linalg.det(Df), 0, atol=1e-9):\n",
        "            print(\"Singular jacobian\")\n",
        "            return None\n",
        "        \n",
        "        x[:] = x - np.linalg.solve(Df, f(x))\n",
        "\n",
        "    return x, i\n",
        "\n",
        "def scalar_newton(f, x0, dx: float, tol=1e-6, max_itr=1e4):\n",
        "    if type(x0) != np.ndarray:\n",
        "        x0 = np.array([x0])\n",
        "    \n",
        "    ans = newtons_method(f, x0, dx, tol=tol, max_itr=max_itr)\n",
        "    if ans is None:\n",
        "        return None, 0\n",
        "    else:    \n",
        "        return ans[0][0], ans[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fB2CO5yPRj4s"
      },
      "source": [
        "### Arnoldi iteration\n",
        "\n",
        "I used the algorithm in the lecturenotes with slight modifications. Having problems with the algorithm dividing by zero I (with slight inpiration from Wikipedia, heh.) added a test `H[j + 1, j] > 1e-12` to ensure that no `nan` values occur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDJtku63Rj4t",
        "colab": {}
      },
      "source": [
        "def arnoldi_iteration(A, b, k: int):\n",
        "    if type(A) != np.ndarray or A.ndim != 2:\n",
        "        raise Exception(\"A matrix format not recogniced.\")\n",
        "    if type(b) != np.ndarray or b.ndim != 1:\n",
        "        raise Exception(\"b vector format not recogniced.\")\n",
        "    if A.shape[0] != b.size:\n",
        "        raise Exception(\"Shapes of A and b does not agree.\")\n",
        "    \n",
        "    H = np.zeros((k + 1, k))\n",
        "    Q = np.zeros((A.shape[0], k + 1))\n",
        "    Q[:, 0] = b / np.linalg.norm(b)\n",
        "    \n",
        "    for j in range(k):\n",
        "        v = A.dot(Q[:, j])\n",
        "        for i in range(j + 1):\n",
        "            H[i, j] = np.dot(Q[:, i].conj(), v)\n",
        "            v = v - H[i, j] * Q[:, i]\n",
        "\n",
        "        H[j + 1, j] = np.linalg.norm(v)\n",
        "        if H[j + 1, j] > 1e-12:\n",
        "            Q[:, j + 1] = v / H[j + 1, j]\n",
        "        else:\n",
        "            break\n",
        "    return Q, H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kf274YzBRj48"
      },
      "source": [
        "### GMRES algorithm\n",
        "\n",
        "Since we already written a least squares solver in a previous lab I use Numpy's `numpy.linalg.lstsq` method. To the algorithm in the lecture notes I've also added a maximum number of itterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ARnPi-VMRj49",
        "colab": {}
      },
      "source": [
        "def gmres(A, b, max_itr=None, tol=1e-6):\n",
        "    if type(A) != np.ndarray or A.ndim != 2:\n",
        "        raise Exception(\"A matrix format not recogniced.\")\n",
        "    if type(b) != np.ndarray or b.ndim != 1:\n",
        "        raise Exception(\"b vector format not recogniced.\")\n",
        "    if A.shape[0] != b.size:\n",
        "        raise Exception(\"Shapes of A and b does not agree.\")\n",
        "    \n",
        "    norm_b = np.linalg.norm(b)\n",
        "    \n",
        "    Q = np.zeros((b.size, 1))\n",
        "    Q[:, 0] = b[:]/norm_b\n",
        "    \n",
        "    y = None\n",
        "    r = tol * norm_b\n",
        "    \n",
        "    k = 0\n",
        "    while np.linalg.norm(r) >= tol * norm_b:\n",
        "        Q, H = arnoldi_iteration(A, b, k)\n",
        "        y = np.linalg.lstsq(H, norm_b * standard_basis(k+1, 0), rcond=None)[0]\n",
        "        r = H.dot(y)\n",
        "        r[:] = norm_b * standard_basis(k+1, 0) - r[:]\n",
        "        k += 1\n",
        "        if not(max_itr is None) and k >= max_itr:\n",
        "            break\n",
        "    \n",
        "    x = Q[:, 0:k-1].dot(y)\n",
        "    return x, k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SxtzgZLtRj5A"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h__3J5w4L7CT",
        "colab_type": "text"
      },
      "source": [
        "## Iteration algorithms\n",
        "\n",
        "The testing of accuracy of the iteration solvers are very alike. Therefore I defined a `test_iteration_solver` method. It generates random matrix $A$ of size $\\text{max_size} \\times \\text{max_size}$ and a random vector $x$ of size $\\text{max_size}$ and then creates $b = Ax$. It then checks $||x_{est} - x|| \\approx 0$ and $||Ax - b|| \\approx 0$ down to `decimal` decimals. The process is repeated `num_of_tests` times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-B5mIAyKRj5E",
        "colab": {}
      },
      "source": [
        "def test_iteration_solver(solver, decimal=4, num_of_tests=1000, max_size=10, alpha=None):\n",
        "    i = 0\n",
        "    tol = 1e-6\n",
        "\n",
        "    while i < num_of_tests:\n",
        "        n = np.random.randint(1, max_size)\n",
        "        A = 1000 * np.random.rand(n, n)\n",
        "        x_true = np.random.rand(n)\n",
        "        b = A.dot(x_true)\n",
        "        \n",
        "        if np.allclose(np.linalg.det(A), 0, 1e-9):\n",
        "            continue\n",
        "\n",
        "        ans = None\n",
        "        if solver == richardson_iteration:\n",
        "            ans = solver(A, b, alpha, tol=tol)\n",
        "        else:\n",
        "            ans = solver(A, b, tol=tol)\n",
        "        if ans is None:\n",
        "            continue\n",
        "        i += 1\n",
        "\n",
        "        x = ans[0]\n",
        "        \n",
        "        np.testing.assert_allclose(\n",
        "            np.linalg.norm(A.dot(x) - b),\n",
        "            0,\n",
        "            atol=10 * tol)\n",
        "\n",
        "class TestIterationSolvers(unittest.TestCase):\n",
        "    def test_jacobi(self):\n",
        "        test_iteration_solver(jacobi_iteration)\n",
        "                \n",
        "    def test_gauss_seidel(self):\n",
        "        test_iteration_solver(gauss_seidel_iteration)\n",
        "\n",
        "    def test_gmres(self):\n",
        "        test_iteration_solver(gmres)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01tRYtQDI1gA",
        "colab_type": "text"
      },
      "source": [
        "## Newtons method\n",
        "For the scalar Newtons method I generate polynomials with roots spaced along the $x$-axis. I use Newtons method to find these polynomials to find the zeros of the function and then check for accuracy. I checked that $|f(x)|\\approx 0$ and that $|x-r|\\approx 0$ for some root $r$. I calculated the tolerance of $|x-r|$ by using the derivative at the calculated root and using a linear approximation. Then the tolerance in the $x$-axis is given by the contition that\n",
        "$$|x - r| < \\frac{\\text{TOL}}{f'(x)}$$\n",
        "where $\\text{TOL}$ is the tolerance in the $y$-axis.\n",
        "\n",
        "I tested for a $1000$ random polynomials in a predefined (convenient) subspace of polynomials ($\\text{deg} < 10$, $r < \\text{10000}$, $0.1 < |r_n - r_m| < 100$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbDknwBh-6jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rand_polynomial(deg: int, root_max_abs: float, minimal_root_dist: float):\n",
        "    if 2 * root_max_abs < (deg - 1) * minimal_root_dist:\n",
        "        raise Exception(\"Intervall error\")\n",
        "\n",
        "    roots = []\n",
        "    low = -root_max_abs\n",
        "    high = root_max_abs - (deg - 1) * minimal_root_dist\n",
        "    for i in range(deg):\n",
        "        roots.append(random.uniform(low, high))\n",
        "        low = roots[i] + minimal_root_dist\n",
        "        high += minimal_root_dist\n",
        "\n",
        "    def f(x):\n",
        "        y = 1\n",
        "        for root in roots:\n",
        "            y *= (x - root)\n",
        "        return y\n",
        "\n",
        "    return f, roots\n",
        "\n",
        "class TestNewtonScalar(unittest.TestCase):\n",
        "    def test_rand_polynomial(self):\n",
        "        max_deg = 2\n",
        "        max_dist = 100\n",
        "        max_root_max = 10000\n",
        "        tol = 1e-6\n",
        "\n",
        "        for i in range(1000):\n",
        "            root_dist = random.uniform(0.1, max_dist)\n",
        "            deg = random.randint(1, max_deg)\n",
        "            root_max = random.uniform((deg - 1) * root_dist, max_root_max)\n",
        "            \n",
        "            f, roots = get_rand_polynomial(deg, root_max, root_dist)\n",
        "\n",
        "            x0 = random.uniform(-root_max, root_max)\n",
        "            root = scalar_newton(f, x0, tol)[0]\n",
        "\n",
        "            np.testing.assert_allclose(f(root), 0, atol=tol)\n",
        "            is_close = False\n",
        "            dfdx = get_derivative(f, np.array([root]), np.array([1e-6]))[0]\n",
        "            for r in roots:\n",
        "                diff = r - root\n",
        "                if np.allclose(diff, 0, atol=tol/abs(dfdx)):\n",
        "                    is_close = True\n",
        "                    break\n",
        "\n",
        "            assert is_close\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh7QQSSLL0eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f1926116-8a77-46b6-c9af-551edb714f32"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 9.055s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pvacOInMQdP",
        "colab_type": "text"
      },
      "source": [
        "Above we can se that the iterative solvers all solve systems of linear equations. The toleranse-levels are generally accomplished, but not allways (strange...).\n",
        "\n",
        "The method for scalar Newton succeed in all polynomials with zeros not to close together. It can not allways be guaraanteed to succeed since you can create \"deadlocks\", but that is more common in symetric equations as $cos(x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "\n",
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbqFg1rSPC7V",
        "colab_type": "text"
      },
      "source": [
        "Having more time for the lab it would have been interesting to investigate both the number of iterations taken by the different methods, but allso the absolute time. The GMRES has a very different method to the Jacobi and Gauss-Seidel methods, so even thou the number of itterations are fewer the time complexity or absolute time might be very different."
      ]
    }
  ]
}